{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-12T05:50:52.332047Z",
     "start_time": "2025-03-12T05:50:50.814399Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def optimize_datatypes(data):\n",
    "    # Downcast numerical columns\n",
    "    for col in data.select_dtypes(include='int'):\n",
    "        data[col] = pd.to_numeric(data[col], downcast='integer')\n",
    "    for col in data.select_dtypes(include='float'):\n",
    "        data[col] = pd.to_numeric(data[col], downcast='float')\n",
    "    \n",
    "    # Convert categorical columns to category dtype\n",
    "    if 'Hypertension' in data.columns:\n",
    "        data['Hypertension'] = data['Hypertension'].astype('category')\n",
    "    \n",
    "    return data\n",
    "\n",
    "def mainBareBones():\n",
    "    # Load the dataset\n",
    "    file_path = \"diabetes_dataset.csv\"  # Replace with your dataset's file path\n",
    "    print(\"Loading dataset...\")\n",
    "    try:\n",
    "        data = pd.read_csv(file_path)\n",
    "        print(f\"Dataset loaded successfully! Shape: {data.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "        exit()\n",
    "\n",
    "    # Data Cleaning and Preprocessing\n",
    "    print(\"\\nCleaning and preprocessing data...\")\n",
    "    print(f\"Missing values before cleaning: {data.isnull().sum().sum()}\")\n",
    "    data.fillna(data.mean(numeric_only=True), inplace=True)  # Replace NaNs in numeric columns\n",
    "    print(f\"Missing values after cleaning: {data.isnull().sum().sum()}\")\n",
    "\n",
    "    # Optimize data types\n",
    "    print(\"\\nOptimizing data types...\")\n",
    "    data = optimize_datatypes(data)\n",
    "\n",
    "    # Encode categorical variables (if applicable)\n",
    "    if 'Hypertension' in data.columns:\n",
    "        data['Hypertension'] = data['Hypertension'].cat.codes\n",
    "\n",
    "    # Separate features (X) and target (y)\n",
    "    print(\"\\nSeparating features and target variable...\")\n",
    "    X = data.drop('Outcome', axis=1)\n",
    "    y = data['Outcome']\n",
    "    print(f\"Features shape: {X.shape}, Target shape: {y.shape}\")\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    print(\"\\nSplitting data into training and testing sets...\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    print(f\"Training set shape: {X_train.shape}, Testing set shape: {X_test.shape}\")\n",
    "\n",
    "    # Scale features for better performance\n",
    "    print(\"\\nScaling features...\")\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Initialize and train the logistic regression model\n",
    "    print(\"\\nTraining the logistic regression model...\")\n",
    "    model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"Model training completed!\")\n",
    "\n",
    "    # Make predictions\n",
    "    print(\"\\nMaking predictions on the test set...\")\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    print(\"\\nEvaluating the model...\")\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mainBareBones()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset loaded successfully! Shape: (9538, 17)\n",
      "\n",
      "Cleaning and preprocessing data...\n",
      "Missing values before cleaning: 0\n",
      "Missing values after cleaning: 0\n",
      "\n",
      "Optimizing data types...\n",
      "\n",
      "Separating features and target variable...\n",
      "Features shape: (9538, 16), Target shape: (9538,)\n",
      "\n",
      "Splitting data into training and testing sets...\n",
      "Training set shape: (7630, 16), Testing set shape: (1908, 16)\n",
      "\n",
      "Scaling features...\n",
      "\n",
      "Training the logistic regression model...\n",
      "Model training completed!\n",
      "\n",
      "Making predictions on the test set...\n",
      "\n",
      "Evaluating the model...\n",
      "Accuracy: 99.32%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      1275\n",
      "           1       1.00      0.98      0.99       633\n",
      "\n",
      "    accuracy                           0.99      1908\n",
      "   macro avg       0.99      0.99      0.99      1908\n",
      "weighted avg       0.99      0.99      0.99      1908\n",
      "\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T05:50:52.867263Z",
     "start_time": "2025-03-12T05:50:52.410544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import cupy as cp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def optimize_datatypes(data):\n",
    "    # Downcast numerical columns to reduce memory usage\n",
    "    for col in data.select_dtypes(include=['int']):\n",
    "        data[col] = pd.to_numeric(data[col], downcast='integer')\n",
    "    for col in data.select_dtypes(include=['float']):\n",
    "        data[col] = pd.to_numeric(data[col], downcast='float')\n",
    "    \n",
    "    return data\n",
    "\n",
    "def mainCuPY():\n",
    "    # Load the dataset\n",
    "    file_path = \"diabetes_dataset.csv\"  # Replace with your file path\n",
    "    print(\"Loading dataset...\")\n",
    "    try:\n",
    "        data = pd.read_csv(file_path)\n",
    "        print(f\"Dataset loaded successfully! Shape: {data.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "        exit()\n",
    "\n",
    "    # Data Cleaning and Preprocessing\n",
    "    print(\"\\nCleaning and preprocessing data...\")\n",
    "    missing_values_before = data.isnull().sum().sum()\n",
    "    print(f\"Missing values before cleaning: {missing_values_before}\")\n",
    "    data.fillna(data.mean(numeric_only=True), inplace=True)  # Fill NaNs for numeric columns\n",
    "    missing_values_after = data.isnull().sum().sum()\n",
    "    print(f\"Missing values after cleaning: {missing_values_after}\")\n",
    "\n",
    "    # Optimize datatypes\n",
    "    print(\"\\nOptimizing data types...\")\n",
    "    data = optimize_datatypes(data)\n",
    "\n",
    "    # Convert categorical columns (e.g., Hypertension) to integers if necessary\n",
    "    if 'Hypertension' in data.columns:\n",
    "        data['Hypertension'] = data['Hypertension'].astype(int)\n",
    "\n",
    "    # Separate features (X) and target (y)\n",
    "    print(\"\\nSeparating features and target variable...\")\n",
    "    X = data.drop('Outcome', axis=1).values\n",
    "    y = data['Outcome'].values\n",
    "    print(f\"Features shape: {X.shape}, Target shape: {y.shape}\")\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    print(\"\\nSplitting data into training and testing sets...\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    print(f\"Training set shape: {X_train.shape}, Testing set shape: {X_test.shape}\")\n",
    "\n",
    "    # Convert to CuPy arrays for GPU acceleration\n",
    "    print(\"\\nTransferring data to GPU using CuPy...\")\n",
    "    X_train_cp = cp.asarray(X_train, dtype=cp.float32)\n",
    "    X_test_cp = cp.asarray(X_test, dtype=cp.float32)\n",
    "    y_train_cp = cp.asarray(y_train, dtype=cp.int32)\n",
    "    y_test_cp = cp.asarray(y_test, dtype=cp.int32)\n",
    "\n",
    "    # Standardize features\n",
    "    print(\"\\nScaling features...\")\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = cp.asarray(scaler.fit_transform(cp.asnumpy(X_train_cp)))\n",
    "    X_test_scaled = cp.asarray(scaler.transform(cp.asnumpy(X_test_cp)))\n",
    "\n",
    "    # Train the logistic regression model\n",
    "    print(\"\\nTraining the logistic regression model...\")\n",
    "    model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "    model.fit(cp.asnumpy(X_train_scaled), cp.asnumpy(y_train_cp))\n",
    "    print(\"Model training completed!\")\n",
    "\n",
    "    # Make predictions\n",
    "    print(\"\\nMaking predictions on the test set...\")\n",
    "    y_pred = model.predict(cp.asnumpy(X_test_scaled))\n",
    "\n",
    "    # Evaluate the model\n",
    "    print(\"\\nEvaluating the model...\")\n",
    "    accuracy = accuracy_score(cp.asnumpy(y_test_cp), y_pred)\n",
    "    print(f\"Accuracy (CuPy Optimized): {accuracy * 100:.2f}%\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(cp.asnumpy(y_test_cp), y_pred))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mainCuPY()"
   ],
   "id": "e658df7d21fe4c41",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset loaded successfully! Shape: (9538, 17)\n",
      "\n",
      "Cleaning and preprocessing data...\n",
      "Missing values before cleaning: 0\n",
      "Missing values after cleaning: 0\n",
      "\n",
      "Optimizing data types...\n",
      "\n",
      "Separating features and target variable...\n",
      "Features shape: (9538, 16), Target shape: (9538,)\n",
      "\n",
      "Splitting data into training and testing sets...\n",
      "Training set shape: (7630, 16), Testing set shape: (1908, 16)\n",
      "\n",
      "Transferring data to GPU using CuPy...\n",
      "\n",
      "Scaling features...\n",
      "\n",
      "Training the logistic regression model...\n",
      "Model training completed!\n",
      "\n",
      "Making predictions on the test set...\n",
      "\n",
      "Evaluating the model...\n",
      "Accuracy (CuPy Optimized): 99.32%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      1275\n",
      "           1       1.00      0.98      0.99       633\n",
      "\n",
      "    accuracy                           0.99      1908\n",
      "   macro avg       0.99      0.99      0.99      1908\n",
      "weighted avg       0.99      0.99      0.99      1908\n",
      "\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T05:50:53.477786Z",
     "start_time": "2025-03-12T05:50:53.033553Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearnex import patch_sklearn \n",
    "patch_sklearn() # Apply Intel optimizations\n",
    "def optimize_datatypes(data):\n",
    "    # Downcast numerical columns\n",
    "    for col in data.select_dtypes(include='int'):\n",
    "        data[col] = pd.to_numeric(data[col], downcast='integer')\n",
    "    for col in data.select_dtypes(include='float'):\n",
    "        data[col] = pd.to_numeric(data[col], downcast='float')\n",
    "    \n",
    "    # Convert categorical columns to category dtype\n",
    "    if 'Hypertension' in data.columns:\n",
    "        data['Hypertension'] = data['Hypertension'].astype('category')\n",
    "    \n",
    "    return data\n",
    "\n",
    "def mainIntelex():\n",
    "    # Load the dataset\n",
    "    file_path = \"diabetes_dataset.csv\"  # Replace with your dataset's file path\n",
    "    print(\"Loading dataset...\")\n",
    "    try:\n",
    "        data = pd.read_csv(file_path)\n",
    "        print(f\"Dataset loaded successfully! Shape: {data.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "        exit()\n",
    "\n",
    "    # Data Cleaning and Preprocessing\n",
    "    print(\"\\nCleaning and preprocessing data...\")\n",
    "    print(f\"Missing values before cleaning: {data.isnull().sum().sum()}\")\n",
    "    data.fillna(data.mean(numeric_only=True), inplace=True)  # Replace NaNs in numeric columns\n",
    "    print(f\"Missing values after cleaning: {data.isnull().sum().sum()}\")\n",
    "\n",
    "    # Optimize data types\n",
    "    print(\"\\nOptimizing data types...\")\n",
    "    data = optimize_datatypes(data)\n",
    "\n",
    "    # Encode categorical variables (if applicable)\n",
    "    if 'Hypertension' in data.columns:\n",
    "        data['Hypertension'] = data['Hypertension'].cat.codes\n",
    "\n",
    "    # Separate features (X) and target (y)\n",
    "    print(\"\\nSeparating features and target variable...\")\n",
    "    X = data.drop('Outcome', axis=1)\n",
    "    y = data['Outcome']\n",
    "    print(f\"Features shape: {X.shape}, Target shape: {y.shape}\")\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    print(\"\\nSplitting data into training and testing sets...\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    print(f\"Training set shape: {X_train.shape}, Testing set shape: {X_test.shape}\")\n",
    "\n",
    "    # Scale features for better performance\n",
    "    print(\"\\nScaling features...\")\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Initialize and train the logistic regression model\n",
    "    print(\"\\nTraining the logistic regression model...\")\n",
    "    model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"Model training completed!\")\n",
    "\n",
    "    # Make predictions\n",
    "    print(\"\\nMaking predictions on the test set...\")\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    print(\"\\nEvaluating the model...\")\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mainIntelex()"
   ],
   "id": "1dec56d1805f1572",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset loaded successfully! Shape: (9538, 17)\n",
      "\n",
      "Cleaning and preprocessing data...\n",
      "Missing values before cleaning: 0\n",
      "Missing values after cleaning: 0\n",
      "\n",
      "Optimizing data types...\n",
      "\n",
      "Separating features and target variable...\n",
      "Features shape: (9538, 16), Target shape: (9538,)\n",
      "\n",
      "Splitting data into training and testing sets...\n",
      "Training set shape: (7630, 16), Testing set shape: (1908, 16)\n",
      "\n",
      "Scaling features...\n",
      "\n",
      "Training the logistic regression model...\n",
      "Model training completed!\n",
      "\n",
      "Making predictions on the test set...\n",
      "\n",
      "Evaluating the model...\n",
      "Accuracy: 99.32%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      1275\n",
      "           1       1.00      0.98      0.99       633\n",
      "\n",
      "    accuracy                           0.99      1908\n",
      "   macro avg       0.99      0.99      0.99      1908\n",
      "weighted avg       0.99      0.99      0.99      1908\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
