{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-12T05:55:40.893706Z",
     "start_time": "2025-03-12T05:55:39.229619Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from xgboost import DMatrix, train\n",
    "\n",
    "def optimize_datatypes(data):\n",
    "    # Downcast numerical columns to reduce memory usage\n",
    "    for col in data.select_dtypes(include=['int']):\n",
    "        data[col] = pd.to_numeric(data[col], downcast='integer')\n",
    "    for col in data.select_dtypes(include=['float']):\n",
    "        data[col] = pd.to_numeric(data[col], downcast='float')\n",
    "    \n",
    "    return data\n",
    "\n",
    "def mainBareBones():\n",
    "    # Load the dataset\n",
    "    file_path = \"diabetes_dataset.csv\"  # Replace with the path to your CSV file\n",
    "    print(\"Loading dataset...\")\n",
    "    try:\n",
    "        data = pd.read_csv(file_path)\n",
    "        print(f\"Dataset loaded successfully! Shape: {data.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "        exit()\n",
    "\n",
    "    # Data Cleaning and Preprocessing\n",
    "    print(\"\\nCleaning and preprocessing data...\")\n",
    "    missing_values_before = data.isnull().sum().sum()\n",
    "    print(f\"Missing values before cleaning: {missing_values_before}\")\n",
    "    data.fillna(data.mean(numeric_only=True), inplace=True)  # Replace NaNs for numeric columns\n",
    "    missing_values_after = data.isnull().sum().sum()\n",
    "    print(f\"Missing values after cleaning: {missing_values_after}\")\n",
    "\n",
    "    # Optimize datatypes\n",
    "    print(\"\\nOptimizing datatypes...\")\n",
    "    data = optimize_datatypes(data)\n",
    "\n",
    "    # Convert categorical columns (e.g., Hypertension) to integers\n",
    "    print(\"Converting categorical columns to integers...\")\n",
    "    if 'Hypertension' in data.columns:\n",
    "        data['Hypertension'] = data['Hypertension'].astype(int)\n",
    "\n",
    "    # Separate features (X) and target (y)\n",
    "    print(\"\\nSeparating features and target variable...\")\n",
    "    X = data.drop('Outcome', axis=1).values\n",
    "    y = data['Outcome'].values\n",
    "    print(f\"Features shape: {X.shape}, Target shape: {y.shape}\")\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    print(\"\\nSplitting data into training and testing sets...\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    print(f\"Training set shape: {X_train.shape}, Testing set shape: {X_test.shape}\")\n",
    "\n",
    "    print(\"\\nConverting data to DMatrix format for XGBoost...\")\n",
    "    dtrain = DMatrix(X_train, label=y_train)\n",
    "    dtest = DMatrix(X_test, label=y_test)\n",
    "\n",
    "    # Parameters for XGBoost\n",
    "    params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'tree_method': 'hist',  # Optimized for GPU\n",
    "        'device': 'cuda:0', # Use GPU,\n",
    "        'random_state': 42 \n",
    "    }\n",
    "\n",
    "    # Train the model\n",
    "    print(\"\\nTraining the XGBoost model...\")\n",
    "    model = train(params, dtrain)\n",
    "    print(\"Model training completed!\")\n",
    "\n",
    "    # Make predictions\n",
    "    print(\"\\nMaking predictions on the test set...\")\n",
    "    y_pred = (model.predict(dtest) > 0.5).astype(int)\n",
    "\n",
    "    # Evaluate the model\n",
    "    print(\"\\nEvaluating the model...\")\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy (Optimized): {accuracy * 100:.2f}%\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mainBareBones()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset loaded successfully! Shape: (9538, 17)\n",
      "\n",
      "Cleaning and preprocessing data...\n",
      "Missing values before cleaning: 0\n",
      "Missing values after cleaning: 0\n",
      "\n",
      "Optimizing datatypes...\n",
      "Converting categorical columns to integers...\n",
      "\n",
      "Separating features and target variable...\n",
      "Features shape: (9538, 16), Target shape: (9538,)\n",
      "\n",
      "Splitting data into training and testing sets...\n",
      "Training set shape: (7630, 16), Testing set shape: (1908, 16)\n",
      "\n",
      "Converting data to DMatrix format for XGBoost...\n",
      "\n",
      "Training the XGBoost model...\n",
      "Model training completed!\n",
      "\n",
      "Making predictions on the test set...\n",
      "\n",
      "Evaluating the model...\n",
      "Accuracy (Optimized): 99.90%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1275\n",
      "           1       1.00      1.00      1.00       633\n",
      "\n",
      "    accuracy                           1.00      1908\n",
      "   macro avg       1.00      1.00      1.00      1908\n",
      "weighted avg       1.00      1.00      1.00      1908\n",
      "\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T05:55:41.426146Z",
     "start_time": "2025-03-12T05:55:40.898817Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import cupy as cp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from xgboost import DMatrix, train\n",
    "\n",
    "def optimize_datatypes(data):\n",
    "    # Downcast numerical columns to reduce memory usage\n",
    "    for col in data.select_dtypes(include=['int']):\n",
    "        data[col] = pd.to_numeric(data[col], downcast='integer')\n",
    "    for col in data.select_dtypes(include=['float']):\n",
    "        data[col] = pd.to_numeric(data[col], downcast='float')\n",
    "    \n",
    "    return data\n",
    "\n",
    "def mainCuPY():\n",
    "    # Load the dataset\n",
    "    file_path = \"diabetes_dataset.csv\"  # Replace with the path to your CSV file\n",
    "    print(\"Loading dataset...\")\n",
    "    try:\n",
    "        data = pd.read_csv(file_path)\n",
    "        print(f\"Dataset loaded successfully! Shape: {data.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "        exit()\n",
    "\n",
    "    # Data Cleaning and Preprocessing\n",
    "    print(\"\\nCleaning and preprocessing data...\")\n",
    "    print(f\"Missing values before cleaning: {data.isnull().sum().sum()}\")\n",
    "    data.fillna(data.mean(numeric_only=True), inplace=True)  # Replace NaNs with column means\n",
    "    print(f\"Missing values after cleaning: {data.isnull().sum().sum()}\")\n",
    "\n",
    "    # Optimize datatypes\n",
    "    print(\"\\nOptimizing datatypes...\")\n",
    "    data = optimize_datatypes(data)\n",
    "\n",
    "    # Convert categorical columns (e.g., Hypertension) to integers\n",
    "    if 'Hypertension' in data.columns:\n",
    "        data['Hypertension'] = data['Hypertension'].astype(int)\n",
    "\n",
    "    # Separate features (X) and target (y)\n",
    "    print(\"\\nSeparating features and target variable...\")\n",
    "    X = data.drop('Outcome', axis=1).values\n",
    "    y = data['Outcome'].values\n",
    "    print(f\"Features shape: {X.shape}, Target shape: {y.shape}\")\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    print(\"\\nSplitting data into training and testing sets...\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    print(f\"Training set shape: {X_train.shape}, Testing set shape: {X_test.shape}\")\n",
    "\n",
    "    # Convert to CuPy arrays for GPU acceleration\n",
    "    print(\"\\nTransferring data to GPU...\")\n",
    "    X_train_cp = cp.asarray(X_train, dtype=cp.float32)\n",
    "    X_test_cp = cp.asarray(X_test, dtype=cp.float32)\n",
    "    y_train_cp = cp.asarray(y_train, dtype=cp.int32)\n",
    "    y_test_cp = cp.asarray(y_test, dtype=cp.int32)\n",
    "\n",
    "    print(\"\\nConverting data to DMatrix format for XGBoost...\")\n",
    "    dtrain = DMatrix(X_train_cp, label=y_train_cp)\n",
    "    dtest = DMatrix(X_test_cp, label=y_test_cp)\n",
    "\n",
    "    # Parameters for XGBoost\n",
    "    params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'tree_method': 'hist',  # Optimized for GPU\n",
    "        'device': 'cuda:0',                # Use GPU device 0\n",
    "        'random_state': 42\n",
    "    }\n",
    "\n",
    "    # Train the model\n",
    "    print(\"\\nTraining the XGBoost model...\")\n",
    "    model = train(params, dtrain)\n",
    "    print(\"Model training completed!\")\n",
    "\n",
    "    # Make predictions\n",
    "    print(\"\\nMaking predictions on the test set...\")\n",
    "    y_pred = (cp.asarray(model.predict(dtest)) > 0.5).astype(int)\n",
    "\n",
    "    # Evaluate the model\n",
    "    print(\"\\nEvaluating the model...\")\n",
    "    accuracy = accuracy_score(cp.asnumpy(y_test_cp), cp.asnumpy(y_pred))\n",
    "    print(f\"Accuracy (CuPy Optimized): {accuracy * 100:.2f}%\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(cp.asnumpy(y_test_cp), cp.asnumpy(y_pred)))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mainCuPY()\n"
   ],
   "id": "739acf8d390b081b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset loaded successfully! Shape: (9538, 17)\n",
      "\n",
      "Cleaning and preprocessing data...\n",
      "Missing values before cleaning: 0\n",
      "Missing values after cleaning: 0\n",
      "\n",
      "Optimizing datatypes...\n",
      "\n",
      "Separating features and target variable...\n",
      "Features shape: (9538, 16), Target shape: (9538,)\n",
      "\n",
      "Splitting data into training and testing sets...\n",
      "Training set shape: (7630, 16), Testing set shape: (1908, 16)\n",
      "\n",
      "Transferring data to GPU...\n",
      "\n",
      "Converting data to DMatrix format for XGBoost...\n",
      "\n",
      "Training the XGBoost model...\n",
      "Model training completed!\n",
      "\n",
      "Making predictions on the test set...\n",
      "\n",
      "Evaluating the model...\n",
      "Accuracy (CuPy Optimized): 99.90%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1275\n",
      "           1       1.00      1.00      1.00       633\n",
      "\n",
      "    accuracy                           1.00      1908\n",
      "   macro avg       1.00      1.00      1.00      1908\n",
      "weighted avg       1.00      1.00      1.00      1908\n",
      "\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T05:55:42.141897Z",
     "start_time": "2025-03-12T05:55:41.612238Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from xgboost import DMatrix, train\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()  # Apply Intel optimizations\n",
    "\n",
    "def optimize_datatypes(data):\n",
    "    # Downcast numerical columns to reduce memory usage\n",
    "    for col in data.select_dtypes(include=['int']):\n",
    "        data[col] = pd.to_numeric(data[col], downcast='integer')\n",
    "    for col in data.select_dtypes(include=['float']):\n",
    "        data[col] = pd.to_numeric(data[col], downcast='float')\n",
    "    \n",
    "    return data\n",
    "\n",
    "def mainIntelex():\n",
    "    # Load the dataset\n",
    "    file_path = \"diabetes_dataset.csv\"  # Replace with the path to your CSV file\n",
    "    print(\"Loading dataset...\")\n",
    "    try:\n",
    "        data = pd.read_csv(file_path)\n",
    "        print(f\"Dataset loaded successfully! Shape: {data.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "        exit()\n",
    "\n",
    "    # Data Cleaning and Preprocessing\n",
    "    print(\"\\nCleaning and preprocessing data...\")\n",
    "    missing_values_before = data.isnull().sum().sum()\n",
    "    print(f\"Missing values before cleaning: {missing_values_before}\")\n",
    "    data.fillna(data.mean(numeric_only=True), inplace=True)  # Replace NaNs for numeric columns\n",
    "    missing_values_after = data.isnull().sum().sum()\n",
    "    print(f\"Missing values after cleaning: {missing_values_after}\")\n",
    "\n",
    "    # Optimize datatypes\n",
    "    print(\"\\nOptimizing datatypes...\")\n",
    "    data = optimize_datatypes(data)\n",
    "\n",
    "    # Convert categorical columns (e.g., Hypertension) to integers\n",
    "    print(\"Converting categorical columns to integers...\")\n",
    "    if 'Hypertension' in data.columns:\n",
    "        data['Hypertension'] = data['Hypertension'].astype(int)\n",
    "\n",
    "    # Separate features (X) and target (y)\n",
    "    print(\"\\nSeparating features and target variable...\")\n",
    "    X = data.drop('Outcome', axis=1).values\n",
    "    y = data['Outcome'].values\n",
    "    print(f\"Features shape: {X.shape}, Target shape: {y.shape}\")\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    print(\"\\nSplitting data into training and testing sets...\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    print(f\"Training set shape: {X_train.shape}, Testing set shape: {X_test.shape}\")\n",
    "\n",
    "    print(\"\\nConverting data to DMatrix format for XGBoost...\")\n",
    "    dtrain = DMatrix(X_train, label=y_train)\n",
    "    dtest = DMatrix(X_test, label=y_test)\n",
    "\n",
    "    # Parameters for XGBoost\n",
    "    params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'tree_method': 'hist',  # Optimized for GPU\n",
    "        'device': 'cuda:0', # Use GPU,\n",
    "        'random_state': 42 \n",
    "    }\n",
    "\n",
    "    # Train the model\n",
    "    print(\"\\nTraining the XGBoost model...\")\n",
    "    model = train(params, dtrain)\n",
    "    print(\"Model training completed!\")\n",
    "\n",
    "    # Make predictions\n",
    "    print(\"\\nMaking predictions on the test set...\")\n",
    "    y_pred = (model.predict(dtest) > 0.5).astype(int)\n",
    "\n",
    "    # Evaluate the model\n",
    "    print(\"\\nEvaluating the model...\")\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy (Optimized): {accuracy * 100:.2f}%\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mainIntelex()"
   ],
   "id": "e4d98f5665db85cc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset loaded successfully! Shape: (9538, 17)\n",
      "\n",
      "Cleaning and preprocessing data...\n",
      "Missing values before cleaning: 0\n",
      "Missing values after cleaning: 0\n",
      "\n",
      "Optimizing datatypes...\n",
      "Converting categorical columns to integers...\n",
      "\n",
      "Separating features and target variable...\n",
      "Features shape: (9538, 16), Target shape: (9538,)\n",
      "\n",
      "Splitting data into training and testing sets...\n",
      "Training set shape: (7630, 16), Testing set shape: (1908, 16)\n",
      "\n",
      "Converting data to DMatrix format for XGBoost...\n",
      "\n",
      "Training the XGBoost model...\n",
      "Model training completed!\n",
      "\n",
      "Making predictions on the test set...\n",
      "\n",
      "Evaluating the model...\n",
      "Accuracy (Optimized): 99.90%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1275\n",
      "           1       1.00      1.00      1.00       633\n",
      "\n",
      "    accuracy                           1.00      1908\n",
      "   macro avg       1.00      1.00      1.00      1908\n",
      "weighted avg       1.00      1.00      1.00      1908\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T05:55:42.201428Z",
     "start_time": "2025-03-12T05:55:42.199075Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "3e459eb2d7a64e75",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
