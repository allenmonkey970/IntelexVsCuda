{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def optimize_dtypes(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'float64':\n",
    "            df[col] = pd.to_numeric(df[col], downcast='float')\n",
    "        elif df[col].dtype == 'int64':\n",
    "            df[col] = pd.to_numeric(df[col], downcast='integer')\n",
    "    return df\n",
    "\n",
    "def mainBareBones():\n",
    "    # Load dataset\n",
    "    print(\"Loading dataset...\")\n",
    "    try:\n",
    "        df = pd.read_csv('Active_Wiretap_dataset.csv', header=None, low_memory=False)\n",
    "        labels = pd.read_csv('Active_Wiretap_labels.csv', names=['label'], header=None, low_memory=False)\n",
    "\n",
    "        min_rows = min(len(df), len(labels))\n",
    "        df = df.iloc[:min_rows]\n",
    "        labels = labels.iloc[:min_rows]\n",
    "        labels['label'] = pd.to_numeric(labels['label'], errors='coerce')\n",
    "\n",
    "        print(f\"Dataset shape: {df.shape}\")\n",
    "        print(f\"Labels shape: {labels.shape}\")\n",
    "        print(f\"Label values found: {labels['label'].unique()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {str(e)}\")\n",
    "        exit()\n",
    "\n",
    "    # Preprocess and clean data\n",
    "    print(\"\\nPreprocessing data...\")\n",
    "    df.columns = [f\"feature_{i}\" for i in range(df.shape[1])]\n",
    "    df['label'] = labels['label']\n",
    "    df = optimize_dtypes(df)\n",
    "    df = df.dropna()\n",
    "    df = df[df['label'].notna()]\n",
    "    print(f\"Shape after cleaning: {df.shape}\")\n",
    "\n",
    "    # Split features and labels\n",
    "    X = df.drop('label', axis=1)\n",
    "    y = df['label']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Feature selection\n",
    "    print(\"Performing feature selection...\")\n",
    "    selector = SelectKBest(score_func=f_classif, k=min(30, X.shape[1]))\n",
    "    X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "    X_test_selected = selector.transform(X_test)\n",
    "\n",
    "    # Train model\n",
    "    print(\"\\nTraining the model...\")\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        max_depth=10,\n",
    "        class_weight='balanced'\n",
    "    )\n",
    "    model.fit(X_train_selected, y_train)\n",
    "\n",
    "    # Predictions and evaluation\n",
    "    print(\"Making predictions...\")\n",
    "    y_pred = model.predict(X_test_selected)\n",
    "\n",
    "    print(\"\\nModel Evaluation:\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    print(\"\\nProcess completed!\")\n",
    "    print(f\"Total samples: {len(df)}\")\n",
    "    print(f\"Number of features: {X.shape[1]}\")\n",
    "    print(f\"Number of selected features: {X_train_selected.shape[1]}\")\n",
    "    print(f\"Label distribution:\\n{y.value_counts()}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mainBareBones()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import cupy as cp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def optimize_dtypes(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'float64':\n",
    "            df[col] = pd.to_numeric(df[col], downcast='float')\n",
    "        elif df[col].dtype == 'int64':\n",
    "            df[col] = pd.to_numeric(df[col], downcast='integer')\n",
    "    return df\n",
    "\n",
    "def maincuPY():\n",
    "    # Load dataset\n",
    "    print(\"Loading dataset...\")\n",
    "    try:\n",
    "        df = pd.read_csv('Active_Wiretap_dataset.csv', header=None, low_memory=False)\n",
    "        labels = pd.read_csv('Active_Wiretap_labels.csv', names=['label'], header=None, low_memory=False)\n",
    "\n",
    "        # Ensure datasets have the same number of rows\n",
    "        min_rows = min(len(df), len(labels))\n",
    "        df = df.iloc[:min_rows]\n",
    "        labels = labels.iloc[:min_rows]\n",
    "        labels['label'] = pd.to_numeric(labels['label'], errors='coerce')\n",
    "\n",
    "        print(f\"Dataset shape: {df.shape}\")\n",
    "        print(f\"Labels shape: {labels.shape}\")\n",
    "        print(f\"Label values found: {labels['label'].unique()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {str(e)}\")\n",
    "        exit()\n",
    "\n",
    "    # Preprocess and clean data\n",
    "    print(\"\\nPreprocessing data...\")\n",
    "    df.columns = [f\"feature_{i}\" for i in range(df.shape[1])]\n",
    "    df['label'] = labels['label']\n",
    "    df = optimize_dtypes(df)\n",
    "    df = df.dropna()\n",
    "    df = df[df['label'].notna()]\n",
    "    print(f\"Shape after cleaning: {df.shape}\")\n",
    "\n",
    "    # Split features and labels\n",
    "    X = df.drop('label', axis=1).to_numpy(dtype=cp.float32)\n",
    "    y = df['label'].to_numpy(dtype=cp.float32)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Feature selection\n",
    "    print(\"Performing feature selection...\")\n",
    "    X_train_cpu = cp.asnumpy(X_train)  # Convert to NumPy for sklearn\n",
    "    y_train_cpu = cp.asnumpy(y_train)\n",
    "    selector = SelectKBest(score_func=f_classif, k=min(30, X.shape[1]))\n",
    "    X_train_selected_cpu = selector.fit_transform(X_train_cpu, y_train_cpu)\n",
    "    X_test_selected_cpu = selector.transform(cp.asnumpy(X_test))\n",
    "\n",
    "    # Convert back to CuPy\n",
    "    X_train_selected = cp.array(X_train_selected_cpu, dtype=cp.float32)\n",
    "    X_test_selected = cp.array(X_test_selected_cpu, dtype=cp.float32)\n",
    "\n",
    "    # Train model\n",
    "    print(\"\\nTraining the model...\")\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        max_depth=10,\n",
    "        class_weight='balanced'\n",
    "    )\n",
    "    model.fit(cp.asnumpy(X_train_selected), cp.asnumpy(y_train))  # Convert CuPy to NumPy for sklearn\n",
    "\n",
    "    # Predictions and evaluation\n",
    "    print(\"Making predictions...\")\n",
    "    y_pred = model.predict(cp.asnumpy(X_test_selected))  # Predictions on NumPy arrays\n",
    "\n",
    "    # Evaluate model\n",
    "    print(\"\\nModel Evaluation:\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(cp.asnumpy(y_test), y_pred))\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(cp.asnumpy(y_test), y_pred))\n",
    "\n",
    "    # Summary information\n",
    "    print(\"\\nProcess completed!\")\n",
    "    print(f\"Total samples: {len(df)}\")\n",
    "    print(f\"Number of features: {X.shape[1]}\")\n",
    "    print(f\"Number of selected features: {X_train_selected.shape[1]}\")\n",
    "    print(f\"Label distribution:\\n{cp.bincount(cp.array(y, dtype=cp.int32))}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    maincuPY()\n"
   ],
   "id": "757178f5bdb25e8b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearnex import patch_sklearn  \n",
    "patch_sklearn()  # Apply Scikit-learn algorithms\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "def optimize_dtypes(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'float64':\n",
    "            df[col] = pd.to_numeric(df[col], downcast='float')\n",
    "        elif df[col].dtype == 'int64':\n",
    "            df[col] = pd.to_numeric(df[col], downcast='integer')\n",
    "    return df\n",
    "\n",
    "def mainIntelex():\n",
    "    # Load dataset\n",
    "    print(\"Loading dataset...\")\n",
    "    try:\n",
    "        df = pd.read_csv('Active_Wiretap_dataset.csv', header=None, low_memory=False)\n",
    "        labels = pd.read_csv('Active_Wiretap_labels.csv', names=['label'], header=None, low_memory=False)\n",
    "\n",
    "        min_rows = min(len(df), len(labels))\n",
    "        df = df.iloc[:min_rows]\n",
    "        labels = labels.iloc[:min_rows]\n",
    "        labels['label'] = pd.to_numeric(labels['label'], errors='coerce')\n",
    "\n",
    "        print(f\"Dataset shape: {df.shape}\")\n",
    "        print(f\"Labels shape: {labels.shape}\")\n",
    "        print(f\"Label values found: {labels['label'].unique()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {str(e)}\")\n",
    "        exit()\n",
    "\n",
    "    # Preprocess and clean data\n",
    "    print(\"\\nPreprocessing data...\")\n",
    "    df.columns = [f\"feature_{i}\" for i in range(df.shape[1])]\n",
    "    df['label'] = labels['label']\n",
    "    df = optimize_dtypes(df)\n",
    "    df = df.dropna()\n",
    "    df = df[df['label'].notna()]\n",
    "    print(f\"Shape after cleaning: {df.shape}\")\n",
    "\n",
    "    # Split features and labels\n",
    "    X = df.drop('label', axis=1)\n",
    "    y = df['label']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Feature selection\n",
    "    print(\"Performing feature selection...\")\n",
    "    selector = SelectKBest(score_func=f_classif, k=min(30, X.shape[1]))\n",
    "    X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "    X_test_selected = selector.transform(X_test)\n",
    "\n",
    "    # Train model\n",
    "    print(\"\\nTraining the model...\")\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        max_depth=10,\n",
    "        class_weight='balanced'\n",
    "    )\n",
    "    model.fit(X_train_selected, y_train)\n",
    "\n",
    "    # Predictions and evaluation\n",
    "    print(\"Making predictions...\")\n",
    "    y_pred = model.predict(X_test_selected)\n",
    "\n",
    "    print(\"\\nModel Evaluation:\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    print(\"\\nProcess completed!\")\n",
    "    print(f\"Total samples: {len(df)}\")\n",
    "    print(f\"Number of features: {X.shape[1]}\")\n",
    "    print(f\"Number of selected features: {X_train_selected.shape[1]}\")\n",
    "    print(f\"Label distribution:\\n{y.value_counts()}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mainIntelex()\n"
   ],
   "id": "9552da8b9561108e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "400ebc0ad0096dcb",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
