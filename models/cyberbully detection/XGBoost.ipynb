{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-14T00:40:40.676084Z",
     "start_time": "2025-03-14T00:40:25.214363Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def mainBareBones():\n",
    "    # Load the dataset\n",
    "    data = pd.read_csv('final_hateXplain.csv', dtype={\n",
    "        'comment': 'string',  \n",
    "        'label': 'category', \n",
    "        'Race': 'category',\n",
    "        'Religion': 'category',\n",
    "        'Gender': 'category',\n",
    "        'Sexual Orientation': 'category',\n",
    "        'Miscellaneous': 'category'\n",
    "    })\n",
    "\n",
    "    # Preprocessing\n",
    "    # Fill missing values in the 'comment' column\n",
    "    data['comment'] = data['comment'].fillna('')\n",
    "\n",
    "    # Encode the 'label' column (e.g., normal, offensive, hatespeech)\n",
    "    label_encoder = LabelEncoder()\n",
    "    data['label'] = label_encoder.fit_transform(data['label'])\n",
    "\n",
    "    # TF-IDF Vectorization for the 'comment' column\n",
    "    tfidf = TfidfVectorizer(max_features=5000) \n",
    "    X = tfidf.fit_transform(data['comment'])\n",
    "\n",
    "    # Target variable\n",
    "    y = data['label']\n",
    "\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # XGBoost Model\n",
    "    model = XGBClassifier(eval_metric='mlogloss')\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions on test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluation\n",
    "    print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mainBareBones()"
   ],
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 50\u001B[0m\n\u001B[0;32m     47\u001B[0m     \u001B[38;5;28mprint\u001B[39m(classification_report(y_test, y_pred, target_names\u001B[38;5;241m=\u001B[39mlabel_encoder\u001B[38;5;241m.\u001B[39mclasses_))\n\u001B[0;32m     49\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m---> 50\u001B[0m     mainBareBones()\n",
      "Cell \u001B[1;32mIn[1], line 41\u001B[0m, in \u001B[0;36mmainBareBones\u001B[1;34m()\u001B[0m\n\u001B[0;32m     39\u001B[0m \u001B[38;5;66;03m# XGBoost Model\u001B[39;00m\n\u001B[0;32m     40\u001B[0m model \u001B[38;5;241m=\u001B[39m XGBClassifier(eval_metric\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmlogloss\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m---> 41\u001B[0m model\u001B[38;5;241m.\u001B[39mfit(X_train, y_train)\n\u001B[0;32m     43\u001B[0m \u001B[38;5;66;03m# Predictions on test data\u001B[39;00m\n\u001B[0;32m     44\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict(X_test)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\sklearn-env\\Lib\\site-packages\\xgboost\\core.py:726\u001B[0m, in \u001B[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    724\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k, arg \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(sig\u001B[38;5;241m.\u001B[39mparameters, args):\n\u001B[0;32m    725\u001B[0m     kwargs[k] \u001B[38;5;241m=\u001B[39m arg\n\u001B[1;32m--> 726\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\sklearn-env\\Lib\\site-packages\\xgboost\\sklearn.py:1599\u001B[0m, in \u001B[0;36mXGBClassifier.fit\u001B[1;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001B[0m\n\u001B[0;32m   1579\u001B[0m model, metric, params \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_configure_fit(xgb_model, params)\n\u001B[0;32m   1580\u001B[0m train_dmatrix, evals \u001B[38;5;241m=\u001B[39m _wrap_evaluation_matrices(\n\u001B[0;32m   1581\u001B[0m     missing\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmissing,\n\u001B[0;32m   1582\u001B[0m     X\u001B[38;5;241m=\u001B[39mX,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1596\u001B[0m     feature_types\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeature_types,\n\u001B[0;32m   1597\u001B[0m )\n\u001B[1;32m-> 1599\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_Booster \u001B[38;5;241m=\u001B[39m train(\n\u001B[0;32m   1600\u001B[0m     params,\n\u001B[0;32m   1601\u001B[0m     train_dmatrix,\n\u001B[0;32m   1602\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_num_boosting_rounds(),\n\u001B[0;32m   1603\u001B[0m     evals\u001B[38;5;241m=\u001B[39mevals,\n\u001B[0;32m   1604\u001B[0m     early_stopping_rounds\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mearly_stopping_rounds,\n\u001B[0;32m   1605\u001B[0m     evals_result\u001B[38;5;241m=\u001B[39mevals_result,\n\u001B[0;32m   1606\u001B[0m     obj\u001B[38;5;241m=\u001B[39mobj,\n\u001B[0;32m   1607\u001B[0m     custom_metric\u001B[38;5;241m=\u001B[39mmetric,\n\u001B[0;32m   1608\u001B[0m     verbose_eval\u001B[38;5;241m=\u001B[39mverbose,\n\u001B[0;32m   1609\u001B[0m     xgb_model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[0;32m   1610\u001B[0m     callbacks\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallbacks,\n\u001B[0;32m   1611\u001B[0m )\n\u001B[0;32m   1613\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobjective):\n\u001B[0;32m   1614\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobjective \u001B[38;5;241m=\u001B[39m params[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mobjective\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\sklearn-env\\Lib\\site-packages\\xgboost\\core.py:726\u001B[0m, in \u001B[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    724\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k, arg \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(sig\u001B[38;5;241m.\u001B[39mparameters, args):\n\u001B[0;32m    725\u001B[0m     kwargs[k] \u001B[38;5;241m=\u001B[39m arg\n\u001B[1;32m--> 726\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\sklearn-env\\Lib\\site-packages\\xgboost\\training.py:181\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001B[0m\n\u001B[0;32m    179\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cb_container\u001B[38;5;241m.\u001B[39mbefore_iteration(bst, i, dtrain, evals):\n\u001B[0;32m    180\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m--> 181\u001B[0m bst\u001B[38;5;241m.\u001B[39mupdate(dtrain, iteration\u001B[38;5;241m=\u001B[39mi, fobj\u001B[38;5;241m=\u001B[39mobj)\n\u001B[0;32m    182\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cb_container\u001B[38;5;241m.\u001B[39mafter_iteration(bst, i, dtrain, evals):\n\u001B[0;32m    183\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\sklearn-env\\Lib\\site-packages\\xgboost\\core.py:2101\u001B[0m, in \u001B[0;36mBooster.update\u001B[1;34m(self, dtrain, iteration, fobj)\u001B[0m\n\u001B[0;32m   2097\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_assign_dmatrix_features(dtrain)\n\u001B[0;32m   2099\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m fobj \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   2100\u001B[0m     _check_call(\n\u001B[1;32m-> 2101\u001B[0m         _LIB\u001B[38;5;241m.\u001B[39mXGBoosterUpdateOneIter(\n\u001B[0;32m   2102\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle, ctypes\u001B[38;5;241m.\u001B[39mc_int(iteration), dtrain\u001B[38;5;241m.\u001B[39mhandle\n\u001B[0;32m   2103\u001B[0m         )\n\u001B[0;32m   2104\u001B[0m     )\n\u001B[0;32m   2105\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   2106\u001B[0m     pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredict(dtrain, output_margin\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, training\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T00:43:12.996791Z",
     "start_time": "2025-03-14T00:43:11.565987Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cupy as cp\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def mainCuPY():\n",
    "    # Load the dataset with optimized datatypes\n",
    "    data = pd.read_csv('final_hateXplain.csv', dtype={\n",
    "        'comment': 'string',  \n",
    "        'label': 'category', \n",
    "        'Race': 'category',\n",
    "        'Religion': 'category',\n",
    "        'Gender': 'category',\n",
    "        'Sexual Orientation': 'category',\n",
    "        'Miscellaneous': 'category'\n",
    "    })\n",
    "\n",
    "    # Fill missing values in the 'comment' column\n",
    "    data['comment'] = data['comment'].fillna('')\n",
    "\n",
    "    # Encode the 'label' column with LabelEncoder\n",
    "    label_encoder = LabelEncoder()\n",
    "    data['label'] = label_encoder.fit_transform(data['label']).astype('int8')\n",
    "\n",
    "    # TF-IDF Vectorization\n",
    "    tfidf = TfidfVectorizer(max_features=5000)\n",
    "    X = tfidf.fit_transform(data['comment'])\n",
    "\n",
    "    # Convert the sparse matrix to CuPy format\n",
    "    X_cupy = cp.sparse.csr_matrix(X, dtype=cp.float32)\n",
    "\n",
    "    y = cp.asarray(data['label'], dtype=cp.int32)\n",
    "\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_cupy, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # XGBoost parameters\n",
    "    params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'tree_method': 'hist',  # Optimized for GPU\n",
    "        'device': 'cuda',     # Use GPU\n",
    "        'random_state': 42\n",
    "    }\n",
    "\n",
    "    # XGBoost Model\n",
    "    model = XGBClassifier(**params)\n",
    "    model.fit(X_train.get(), y_train.get())  # Convert CuPy arrays to NumPy\n",
    "\n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test.get())\n",
    "\n",
    "    # Evaluation\n",
    "    print(classification_report(y_test.get(), y_pred, target_names=label_encoder.classes_))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mainCuPY()\n"
   ],
   "id": "8c379b9956172b21",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  hatespeech       0.25      0.01      0.02      1325\n",
      "      normal       0.39      0.91      0.55      1502\n",
      "   offensive       0.15      0.07      0.09      1195\n",
      "\n",
      "    accuracy                           0.36      4022\n",
      "   macro avg       0.26      0.33      0.22      4022\n",
      "weighted avg       0.27      0.36      0.24      4022\n",
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T16:46:22.858833Z",
     "start_time": "2025-03-13T16:46:10.248222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()  # Apply Intel optimizations\n",
    "\n",
    "def mainIntelex():\n",
    "    # Load the dataset\n",
    "    data = pd.read_csv('final_hateXplain.csv', dtype={\n",
    "        'comment': 'string',  \n",
    "        'label': 'category', \n",
    "        'Race': 'category',\n",
    "        'Religion': 'category',\n",
    "        'Gender': 'category',\n",
    "        'Sexual Orientation': 'category',\n",
    "        'Miscellaneous': 'category'\n",
    "    })\n",
    "\n",
    "    # Preprocessing\n",
    "    # Fill missing values in the 'comment' column\n",
    "    data['comment'] = data['comment'].fillna('')\n",
    "\n",
    "    # Encode the 'label' column (e.g., normal, offensive, hatespeech)\n",
    "    label_encoder = LabelEncoder()\n",
    "    data['label'] = label_encoder.fit_transform(data['label'])\n",
    "\n",
    "    # TF-IDF Vectorization for the 'comment' column\n",
    "    tfidf = TfidfVectorizer(max_features=5000)  # Adjust max_features as needed\n",
    "    X = tfidf.fit_transform(data['comment'])\n",
    "\n",
    "    # Target variable\n",
    "    y = data['label']\n",
    "\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # XGBoost Model\n",
    "    model = XGBClassifier(eval_metric='mlogloss')\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions on test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluation\n",
    "    print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mainIntelex()"
   ],
   "id": "ff653b4a07dbafbb",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  hatespeech       0.75      0.66      0.71      1325\n",
      "      normal       0.60      0.81      0.69      1502\n",
      "   offensive       0.56      0.39      0.46      1195\n",
      "\n",
      "    accuracy                           0.64      4022\n",
      "   macro avg       0.64      0.62      0.62      4022\n",
      "weighted avg       0.64      0.64      0.63      4022\n",
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6ac166dff67122e8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
