{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-12T05:22:36.496528Z",
     "start_time": "2025-03-12T05:20:05.076880Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def mainBareBones():\n",
    "    # Load the dataset\n",
    "    file_path = \"Loan Prediction.csv\"  # Replace with the path to your dataset\n",
    "    print(\"Loading dataset...\")\n",
    "    try:\n",
    "        data = pd.read_csv(file_path)\n",
    "        print(f\"Dataset loaded successfully! Shape: {data.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "        exit()\n",
    "\n",
    "    # Data Cleaning\n",
    "    print(\"\\nCleaning and preprocessing data...\")\n",
    "    missing_values_before = data.isnull().sum().sum()\n",
    "    print(f\"Missing values before cleaning: {missing_values_before}\")\n",
    "    \n",
    "    # Fill missing values for categorical and numerical columns\n",
    "    for col in data.columns:\n",
    "        if data[col].dtype == 'object':  # Categorical columns\n",
    "            data[col] = data[col].fillna(data[col].mode()[0])\n",
    "        else:  # Numerical columns\n",
    "            data[col] = data[col].fillna(data[col].median())\n",
    "    \n",
    "    missing_values_after = data.isnull().sum().sum()\n",
    "    print(f\"Missing values after cleaning: {missing_values_after}\")\n",
    "\n",
    "    # Convert categorical variables to numeric\n",
    "    print(\"Converting categorical variables to numeric with one-hot encoding...\")\n",
    "    categorical_columns = ['Married/Single', 'House_Ownership', 'Car_Ownership', 'Profession', 'CITY', 'STATE']\n",
    "    data = pd.get_dummies(data, columns=categorical_columns, drop_first=True)\n",
    "    print(f\"Data shape after encoding: {data.shape}\")\n",
    "\n",
    "    # Feature-target split\n",
    "    print(\"\\nSeparating features and target variable...\")\n",
    "    X = data.drop(columns=['Risk_Flag', 'Id'])  # Dropping Id and target column\n",
    "    y = data['Risk_Flag']\n",
    "    print(f\"Features shape: {X.shape}, Target shape: {y.shape}\")\n",
    "\n",
    "    # Train-test split\n",
    "    print(\"\\nSplitting data into training and testing sets...\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    print(f\"Training set shape: {X_train.shape}, Testing set shape: {X_test.shape}\")\n",
    "\n",
    "    # Train Random Forest model\n",
    "    print(\"\\nTraining the Random Forest classifier...\")\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"Model training completed!\")\n",
    "\n",
    "    # Make predictions\n",
    "    print(\"\\nMaking predictions on the test set...\")\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    print(\"\\nEvaluating the model...\")\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mainBareBones()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset loaded successfully! Shape: (252000, 13)\n",
      "\n",
      "Cleaning and preprocessing data...\n",
      "Missing values before cleaning: 0\n",
      "Missing values after cleaning: 0\n",
      "Converting categorical variables to numeric with one-hot encoding...\n",
      "Data shape after encoding: (252000, 405)\n",
      "\n",
      "Separating features and target variable...\n",
      "Features shape: (252000, 403), Target shape: (252000,)\n",
      "\n",
      "Splitting data into training and testing sets...\n",
      "Training set shape: (201600, 403), Testing set shape: (50400, 403)\n",
      "\n",
      "Training the Random Forest classifier...\n",
      "Model training completed!\n",
      "\n",
      "Making predictions on the test set...\n",
      "\n",
      "Evaluating the model...\n",
      "Accuracy: 89.85%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94     44147\n",
      "           1       0.60      0.54      0.57      6253\n",
      "\n",
      "    accuracy                           0.90     50400\n",
      "   macro avg       0.77      0.74      0.75     50400\n",
      "weighted avg       0.89      0.90      0.90     50400\n",
      "\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T05:27:33.523097Z",
     "start_time": "2025-03-12T05:22:36.508031Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cupy as cp  # Import CuPy\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier  # Use Random Forest\n",
    "import numpy as np  # Import NumPy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "def mainCuPY():\n",
    "    # Load the dataset\n",
    "    file_path = \"Loan Prediction.csv\"  # Replace with the path to your dataset\n",
    "    print(\"Loading dataset...\")\n",
    "    try:\n",
    "        data = pd.read_csv(file_path)\n",
    "        print(f\"Dataset loaded successfully! Shape: {data.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "        exit()\n",
    "\n",
    "    # Data Cleaning\n",
    "    print(\"\\nCleaning and preprocessing data...\")\n",
    "    missing_values_before = data.isnull().sum().sum()\n",
    "    print(f\"Missing values before cleaning: {missing_values_before}\")\n",
    "    \n",
    "    # Fill missing values for categorical and numerical columns\n",
    "    for col in data.columns:\n",
    "        if data[col].dtype == 'object':  # Categorical columns\n",
    "            data[col] = data[col].fillna(data[col].mode()[0])\n",
    "        else:  # Numerical columns\n",
    "            data[col] = data[col].fillna(data[col].median())\n",
    "    \n",
    "    missing_values_after = data.isnull().sum().sum()\n",
    "    print(f\"Missing values after cleaning: {missing_values_after}\")\n",
    "\n",
    "    # Convert categorical variables to numeric\n",
    "    print(\"Converting categorical variables to numeric with one-hot encoding...\")\n",
    "    categorical_columns = ['Married/Single', 'House_Ownership', 'Car_Ownership', 'Profession', 'CITY', 'STATE']\n",
    "    data = pd.get_dummies(data, columns=categorical_columns, drop_first=True)\n",
    "    print(f\"Data shape after encoding: {data.shape}\")\n",
    "\n",
    "    # Feature-target split\n",
    "    print(\"\\nSeparating features and target variable...\")\n",
    "    X = data.drop(columns=['Risk_Flag', 'Id'])  # Dropping Id and target column\n",
    "    y = data['Risk_Flag']\n",
    "    print(f\"Features shape: {X.shape}, Target shape: {y.shape}\")\n",
    "\n",
    "    # Convert to NumPy arrays before converting to CuPy arrays\n",
    "    print(\"\\nConverting DataFrame to arrays...\")\n",
    "    X = X.values  # DataFrame to NumPy\n",
    "    y = y.values\n",
    "\n",
    "    # Ensure the data contains no invalid values (inf, -inf, NaN)\n",
    "    print(\"\\nCleaning invalid values in the dataset...\")\n",
    "    X = pd.DataFrame(X).replace([np.inf, -np.inf], np.nan).dropna().values\n",
    "    \n",
    "    # Ensure all columns in X are numeric and cast to float\n",
    "    if not np.issubdtype(X.dtype, np.number):\n",
    "        X = pd.DataFrame(X).apply(pd.to_numeric, errors='coerce').fillna(0).values\n",
    "    \n",
    "    # Explicitly cast X and y to float32\n",
    "    X = X.astype(np.float32)  \n",
    "    y = y.astype(np.float32)  \n",
    "    \n",
    "    # Convert NumPy arrays to CuPy arrays\n",
    "    print(\"\\nTransferring data to GPU...\")\n",
    "    X = cp.asarray(X)\n",
    "    y = cp.asarray(y)\n",
    "    print(\"Data successfully transferred to GPU!\")\n",
    "\n",
    "    # Train-test split\n",
    "    print(\"\\nSplitting data into training and testing sets...\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(cp.asnumpy(X), cp.asnumpy(y), test_size=0.2, random_state=42)\n",
    "    X_train = cp.asarray(X_train)\n",
    "    X_test = cp.asarray(X_test)\n",
    "    y_train = cp.asarray(y_train)\n",
    "    y_test = cp.asarray(y_test)\n",
    "    print(f\"Training set shape: {X_train.shape}, Testing set shape: {X_test.shape}\")\n",
    "\n",
    "    # Train Random Forest model\n",
    "    print(\"\\nTraining the Random Forest classifier...\")\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(cp.asnumpy(X_train), cp.asnumpy(y_train))  # Use `.asnumpy()` to transfer data back to CPU for sklearn\n",
    "    print(\"Model training completed!\")\n",
    "\n",
    "    # Make predictions\n",
    "    print(\"\\nMaking predictions on the test set...\")\n",
    "    y_pred = cp.asarray(model.predict(cp.asnumpy(X_test)))  # Use `.asnumpy()` to transfer data to CPU, then back to GPU\n",
    "\n",
    "    # Evaluate the model\n",
    "    print(\"\\nEvaluating the model...\")\n",
    "    accuracy = accuracy_score(cp.asnumpy(y_test), cp.asnumpy(y_pred))  # Use `.asnumpy()` for sklearn functions\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(cp.asnumpy(y_test), cp.asnumpy(y_pred), zero_division=1))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mainCuPY()"
   ],
   "id": "bae9132265736f00",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset loaded successfully! Shape: (252000, 13)\n",
      "\n",
      "Cleaning and preprocessing data...\n",
      "Missing values before cleaning: 0\n",
      "Missing values after cleaning: 0\n",
      "Converting categorical variables to numeric with one-hot encoding...\n",
      "Data shape after encoding: (252000, 405)\n",
      "\n",
      "Separating features and target variable...\n",
      "Features shape: (252000, 403), Target shape: (252000,)\n",
      "\n",
      "Converting DataFrame to arrays...\n",
      "\n",
      "Cleaning invalid values in the dataset...\n",
      "\n",
      "Transferring data to GPU...\n",
      "Data successfully transferred to GPU!\n",
      "\n",
      "Splitting data into training and testing sets...\n",
      "Training set shape: (201600, 403), Testing set shape: (50400, 403)\n",
      "\n",
      "Training the Random Forest classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T05:30:11.284284Z",
     "start_time": "2025-03-12T05:27:36.706270Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearnex import patch_sklearn \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Apply the patch to accelerate sklearn\n",
    "patch_sklearn()\n",
    "\n",
    "def mainIntelex():\n",
    "    # Load the dataset\n",
    "    file_path = \"Loan Prediction.csv\"  # Replace with the path to your dataset\n",
    "    print(\"Loading dataset...\")\n",
    "    try:\n",
    "        data = pd.read_csv(file_path)\n",
    "        print(f\"Dataset loaded successfully! Shape: {data.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "        exit()\n",
    "\n",
    "    # Data Cleaning\n",
    "    print(\"\\nCleaning and preprocessing data...\")\n",
    "    missing_values_before = data.isnull().sum().sum()\n",
    "    print(f\"Missing values before cleaning: {missing_values_before}\")\n",
    "    \n",
    "    # Fill missing values for categorical and numerical columns\n",
    "    for col in data.columns:\n",
    "        if data[col].dtype == 'object':  # Categorical columns\n",
    "            data[col] = data[col].fillna(data[col].mode()[0])\n",
    "        else:  # Numerical columns\n",
    "            data[col] = data[col].fillna(data[col].median())\n",
    "    \n",
    "    missing_values_after = data.isnull().sum().sum()\n",
    "    print(f\"Missing values after cleaning: {missing_values_after}\")\n",
    "\n",
    "    # Convert categorical variables to numeric\n",
    "    print(\"Converting categorical variables to numeric with one-hot encoding...\")\n",
    "    categorical_columns = ['Married/Single', 'House_Ownership', 'Car_Ownership', 'Profession', 'CITY', 'STATE']\n",
    "    data = pd.get_dummies(data, columns=categorical_columns, drop_first=True)\n",
    "    print(f\"Data shape after encoding: {data.shape}\")\n",
    "\n",
    "    # Feature-target split\n",
    "    print(\"\\nSeparating features and target variable...\")\n",
    "    X = data.drop(columns=['Risk_Flag', 'Id'])  # Dropping Id and target column\n",
    "    y = data['Risk_Flag']\n",
    "    print(f\"Features shape: {X.shape}, Target shape: {y.shape}\")\n",
    "\n",
    "    # Train-test split\n",
    "    print(\"\\nSplitting data into training and testing sets...\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    print(f\"Training set shape: {X_train.shape}, Testing set shape: {X_test.shape}\")\n",
    "\n",
    "    # Train Random Forest model\n",
    "    print(\"\\nTraining the Random Forest classifier...\")\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"Model training completed!\")\n",
    "\n",
    "    # Make predictions\n",
    "    print(\"\\nMaking predictions on the test set...\")\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    print(\"\\nEvaluating the model...\")\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mainIntelex()\n"
   ],
   "id": "ebd60d1f3221e2ec",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset loaded successfully! Shape: (252000, 13)\n",
      "\n",
      "Cleaning and preprocessing data...\n",
      "Missing values before cleaning: 0\n",
      "Missing values after cleaning: 0\n",
      "Converting categorical variables to numeric with one-hot encoding...\n",
      "Data shape after encoding: (252000, 405)\n",
      "\n",
      "Separating features and target variable...\n",
      "Features shape: (252000, 403), Target shape: (252000,)\n",
      "\n",
      "Splitting data into training and testing sets...\n",
      "Training set shape: (201600, 403), Testing set shape: (50400, 403)\n",
      "\n",
      "Training the Random Forest classifier...\n",
      "Model training completed!\n",
      "\n",
      "Making predictions on the test set...\n",
      "\n",
      "Evaluating the model...\n",
      "Accuracy: 89.85%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94     44147\n",
      "           1       0.60      0.54      0.57      6253\n",
      "\n",
      "    accuracy                           0.90     50400\n",
      "   macro avg       0.77      0.74      0.75     50400\n",
      "weighted avg       0.89      0.90      0.90     50400\n",
      "\n"
     ]
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
